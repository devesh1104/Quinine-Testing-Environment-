# LLM Security Testing Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Status: Production Ready](https://img.shields.io/badge/status-production%20ready-brightgreen.svg)]()

> **Enterprise-grade security testing framework for Large Language Models with Prompt Intel API integration**

A comprehensive, production-ready framework for security testing of LLM deployments. Supports multiple model types (local GGUF, API-based, cloud platforms) and includes integration with Prompt Intel API for curated attack prompts.

## ğŸ“‹ Project Status - Week 4

### âœ… Completed Features

#### Core Framework (Weeks 1-3)
- âœ… **Model Adapters**: OpenAI, Anthropic, Gemini, HuggingFace, Ollama, Local GGUF, custom REST
- âœ… **Attack Engine**: 500+ pre-built attacks (OWASP LLM Top 10 coverage)
- âœ… **Evaluation Pipeline**: Multi-method evaluation (LLM judge, semantic analysis, pattern matching)
- âœ… **Orchestrator**: Connection pooling, rate limiting, circuit breaker pattern
- âœ… **Telemetry**: System metrics, GPU monitoring, event logging
- âœ… **Reporting**: HTML/JSON report generation with compliance mapping

#### Prompt Intel Integration (Week 4) ğŸ¯ NEW
- âœ… **PromptintelAdapter**: Full integration with Prompt Intel API
- âœ… **Dynamic Attack Fetching**: Fetch attacks from Prompt Intel library in real-time
- âœ… **Local Model Testing**: Test local GGUF models against Prompt Intel attacks
- âœ… **Combined Orchestrator**: `orchestrator_promptintel_local.py` - Tests local models with Prompt Intel attacks
- âœ… **Configuration System**: `config_promptintel_local.yaml` - Easy setup for Prompt Intel + Local Model tests
- âœ… **Quick Start Script**: `quickstart_promptintel_local.py` - One-command test execution
- âœ… **Professional Reports**: Enhanced HTML reports with detailed attack I/O analysis
- âœ… **Comprehensive Documentation**: Setup guides, implementation docs, examples

### ğŸ¯ What's New This Week

#### New Files Created
1. **`src/orchestrator_promptintel_local.py`** - Main orchestrator for Prompt Intel + Local Model testing
2. **`config/config_promptintel_local.yaml`** - Configuration for Prompt Intel integration
3. **`quickstart_promptintel_local.py`** - Simple entry point for testing
4. **`docs/PROMPTINTEL_LOCAL_SETUP.md`** - Setup and usage guide
5. **`PROMPTINTEL_LOCAL_IMPLEMENTATION.md`** - Detailed implementation guide

#### Enhancements
- Enhanced `PromptintelAdapter` to fetch from `/prompts` endpoint
- Improved HTML report generation with professional styling
- Better error handling and API key validation
- UTF-8 encoding support for reports
- Classification detection from evaluation responses

## ğŸš€ Quick Start

### Option 1: Test Local Model with Prompt Intel Attacks (NEW) â­

```bash
# 1. Get Prompt Intel API Key from https://promptintel.novahunting.ai
# 2. Set environment variable
$env:PROMPTINTEL_API_KEY = "your-api-key-here"

# 3. Run test (easiest way!)
python quickstart_promptintel_local.py
```

### Option 2: Test with Configuration

```python
import asyncio
from src.orchestrator_promptintel_local import PromptIntelLocalTester

async def run():
    tester = PromptIntelLocalTester()
    test_id = await tester.run_test_suite()
    await tester.cleanup()

asyncio.run(run())
```

### Option 3: Test Other Models

```bash
# Test OpenAI model
python src/main.py --config config/config_gemini.yaml

# Test HuggingFace model
python src/main.py --config config/config_huggingface.yaml

# Test Ollama model
python src/main.py --config config/config_ollama.yaml
```

## ğŸ“ Project Structure

```
llm-security-testing-framework/
â”œâ”€â”€ README.md                                    # This file
â”œâ”€â”€ PROMPTINTEL_LOCAL_IMPLEMENTATION.md          # Implementation details
â”œâ”€â”€ requirements.txt                             # Python dependencies
â”œâ”€â”€ requirements-local.txt                       # Local GGUF dependencies
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                                 # Main test runner with CLI
â”‚   â”œâ”€â”€ orchestrator.py                         # Model orchestrator (core component)
â”‚   â”œâ”€â”€ orchestrator_promptintel_local.py       # Prompt Intel + Local Model orchestrator [NEW]
â”‚   â”œâ”€â”€ attack_engine.py                        # Attack execution engine
â”‚   â”œâ”€â”€ evaluator.py                            # Response evaluation pipeline
â”‚   â”œâ”€â”€ reporter.py                             # HTML/JSON report generation
â”‚   â”œâ”€â”€ telemetry.py                            # Metrics and logging
â”‚   â”‚
â”‚   â””â”€â”€ adapters/
â”‚       â”œâ”€â”€ base.py                             # Base adapter interface
â”‚       â”œâ”€â”€ openai_adapter.py                   # OpenAI API support
â”‚       â”œâ”€â”€ anthropic_adapter.py                # Claude API support
â”‚       â”œâ”€â”€ gemini_adapter.py                   # Google Gemini support
â”‚       â”œâ”€â”€ huggingface_adapter.py              # HuggingFace API support
â”‚       â”œâ”€â”€ ollama_adapter.py                   # Ollama local support
â”‚       â”œâ”€â”€ local_gguf_adapter.py               # Local GGUF model support (Mistral, etc.)
â”‚       â””â”€â”€ promptintel_adapter.py              # Prompt Intel API support [ENHANCED]
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml                             # Main configuration
â”‚   â”œâ”€â”€ config_local.yaml                       # Local GGUF model config
â”‚   â”œâ”€â”€ config_ollama.yaml                      # Ollama config
â”‚   â”œâ”€â”€ config_gemini.yaml                      # Gemini config
â”‚   â”œâ”€â”€ config_huggingface.yaml                 # HuggingFace config
â”‚   â”œâ”€â”€ config_promptintel.yaml                 # Prompt Intel config
â”‚   â”œâ”€â”€ config_promptintel_local.yaml           # Prompt Intel + Local Model config [NEW]
â”‚   â”œâ”€â”€ test_suites.yaml                        # Test suite definitions
â”‚   â””â”€â”€ test_configs.yaml                       # Additional test configurations
â”‚
â”œâ”€â”€ attacks/
â”‚   â””â”€â”€ owasp_attacks.yaml                      # OWASP LLM Top 10 attacks (500+)
â”‚
â”œâ”€â”€ quickstart_*.py                             # Quick start scripts
â”‚   â”œâ”€â”€ quickstart.py                           # Default quick start
â”‚   â”œâ”€â”€ quickstart_local.py                     # Local model quick start
â”‚   â”œâ”€â”€ quickstart_ollama.py                    # Ollama quick start
â”‚   â”œâ”€â”€ quickstart_gemini.py                    # Gemini quick start
â”‚   â”œâ”€â”€ quickstart_huggingface.py               # HuggingFace quick start
â”‚   â””â”€â”€ quickstart_promptintel_local.py         # Prompt Intel + Local Model quick start [NEW]
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ QUICKSTART.md                           # Getting started guide
â”‚   â”œâ”€â”€ SETUP.md                                # Detailed setup instructions
â”‚   â”œâ”€â”€ API_KEYS.md                             # API key configuration
â”‚   â”œâ”€â”€ BATCH_TESTING.md                        # Batch testing guide
â”‚   â”œâ”€â”€ DEVELOPER_GUIDE.md                      # For developers
â”‚   â”œâ”€â”€ IMPLEMENTATION_GUIDE.md                 # Implementation details
â”‚   â”œâ”€â”€ THREAT_MODEL.md                         # Threat analysis
â”‚   â”œâ”€â”€ HUGGINGFACE_SETUP.md                    # HuggingFace setup
â”‚   â”œâ”€â”€ OLLAMA_QUICKSTART.md                    # Ollama quick start
â”‚   â”œâ”€â”€ LOCAL_GGUF_SETUP.md                     # Local GGUF setup
â”‚   â””â”€â”€ PROMPTINTEL_LOCAL_SETUP.md              # Prompt Intel setup [NEW]
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ results.jsonl                           # Test results log
â”‚   â””â”€â”€ metrics.jsonl                           # System metrics log
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ report_*.html                           # HTML reports
â”‚   â””â”€â”€ report_*.json                           # JSON reports
â”‚
â”œâ”€â”€ Dockerfile                                  # Docker container setup
â”œâ”€â”€ CHANGELOG.md                                # Version history
â”œâ”€â”€ PROJECT_STRUCTURE.md                        # Detailed structure
â””â”€â”€ PROJECT_STATUS.md                           # Current status
```

## ğŸ¯ Component Overview

### 1. **Model Adapters** (`src/adapters/`)
Universal interface for different model types:
- **API Models**: OpenAI, Anthropic, Gemini, HuggingFace, Cohere
- **Local Models**: Ollama, Local GGUF (Mistral, Llama, etc.)
- **Special**: Prompt Intel API for attack prompts
- **Custom**: REST/GraphQL endpoints

**Key Methods**:
- `initialize()` - Setup connections
- `generate()` - Get model responses
- `health_check()` - Verify connectivity
- `close()` - Cleanup resources

### 2. **Attack Engine** (`src/attack_engine.py`)
Manages attack execution:
- Loads 500+ pre-built attacks from YAML
- Categorized by OWASP LLM Top 10
- Complexity levels: LOW, MEDIUM, HIGH
- Multi-turn conversation support
- Template variable substitution

### 3. **Orchestrator** (`src/orchestrator.py`)
Central coordinator:
- Factory pattern for adapter creation
- Connection pooling for efficiency
- Rate limiting (requests per minute)
- Circuit breaker for fault tolerance
- Request/response caching

### 4. **Evaluation Pipeline** (`src/evaluator.py`)
Multi-method response evaluation:
- **LLM Judge**: Uses another model to evaluate
- **Pattern Matching**: Refusal pattern detection
- **Semantic Analysis**: Text similarity comparison
- **Classification**: REFUSED / PARTIAL_COMPLIANCE / FULL_COMPLIANCE

### 5. **Prompt Intel Integration** (`src/orchestrator_promptintel_local.py`) [NEW]
Combines everything for automated testing:
- Fetches attacks from Prompt Intel API in real-time
- Tests local GGUF models against those attacks
- Evaluates responses with judge model
- Generates professional reports

### 6. **Telemetry Service** (`src/telemetry.py`)
Collects metrics:
- CPU, Memory, Disk usage
- GPU metrics (if available)
- Response latencies
- Token usage
- Attack success/failure rates
- System resource snapshots

### 7. **Report Generator** (`src/reporter.py`)
Creates detailed reports:
- HTML with interactive visualizations
- JSON for programmatic access
- OWASP/ISO/NIST/EU AI Act mapping
- Executive summaries
- Attack I/O details
- Compliance violations list

## ğŸ’» How to Use Prompt Intel Integration

### Prerequisites
1. Python 3.12+
2. Local GGUF model (e.g., Mistral 7B)
3. Prompt Intel API key from https://promptintel.novahunting.ai

### Configuration

Edit `config/config_promptintel_local.yaml`:

```yaml
# Target model to test
target_model:
  name: "mistral-local-gguf"
  type: "local_gguf"
  model_name: "C:\\path\\to\\mistral-7b-instruct.Q4_K_M.gguf"
  parameters:
    temperature: 0.7
    max_tokens: 512
    top_p: 0.95
  timeout: 120
  max_retries: 2

# Judge model for evaluation
judge_model:
  name: "mistral-local-judge"
  type: "local_gguf"
  model_name: "C:\\path\\to\\mistral-7b-instruct.Q4_K_M.gguf"
  parameters:
    temperature: 0.3
    max_tokens: 300
    top_p: 0.95
  timeout: 120
  max_retries: 2

# Prompt Intel API configuration
attacks:
  sources:
    - type: "promptintel_api"
      promptintel:
        endpoint: "https://api.promptintel.novahunting.ai/api/v1"
        api_key: "${PROMPTINTEL_API_KEY}"  # Or set directly
        timeout: 30
        max_retries: 3
  
  categories:
    - "prompt_injection"
    - "jailbreak"
    - "adversarial"
  
  difficulty: "medium"  # low, medium, high
  limit_per_category: 5  # Number of prompts per category

# Execution settings
execution:
  pool_size: 1
  max_concurrent_attacks: 1
  delay_between_attacks_ms: 1000
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    timeout_seconds: 60
```

### Run Test

```bash
# Set API key
$env:PROMPTINTEL_API_KEY = "ak_eed99c5b497c2bb974911e474a827fcd9bd658524700a194c8dfa0a94bd851b2"

# Run test
python quickstart_promptintel_local.py
```

### Output

The framework will:
1. âœ… Fetch attacks from Prompt Intel API
2. âœ… Test each attack against your local model
3. âœ… Evaluate responses with judge model
4. âœ… Generate HTML and JSON reports
5. âœ… Display summary statistics

## ğŸ“Š Report Output

### HTML Report Features
- Professional styling with gradients
- Interactive metrics dashboard
- Detailed attack I/O analysis
- Classification breakdown (Refused/Partial/Compliant)
- Latency and performance metrics
- Timestamp and configuration details

### JSON Report Structure
```json
{
  "test_id": "a1b2c3d4-e5f6-...",
  "timestamp": "2026-02-13T16:16:14.661450",
  "config": {
    "target_model": "mistral-local-gguf",
    "judge_model": "mistral-local-judge",
    "attack_categories": ["jailbreak", "prompt_injection"],
    "total_attacks": 15
  },
  "summary": {
    "total_tests": 15,
    "successful_tests": 15,
    "successful_evaluations": 15
  },
  "results": [
    {
      "attack_index": 1,
      "attack_category": "jailbreak",
      "attack_difficulty": "medium",
      "test_result": {
        "success": true,
        "response": "...",
        "latency_ms": 51250
      },
      "evaluation_result": {
        "success": true,
        "evaluation": "..."
      }
    }
  ]
}
```

## ğŸ”§ Development

### Adding a New Adapter

```python
# src/adapters/my_adapter.py
from adapters.base import BaseModelAdapter, ModelResponse

class MyAdapter(BaseModelAdapter):
    async def initialize(self):
        # Setup connection
        pass
    
    async def generate(self, prompt, system_prompt=None, **kwargs):
        # Call your model
        return ModelResponse(
            content="response",
            model="my-model",
            finish_reason="stop",
            tokens_used=100,
            latency_ms=250,
            raw_response={},
            metadata={}
        )
```

### Adding Custom Attacks

```yaml
# attacks/custom/my-attacks.yaml
attacks:
  - id: "custom-001"
    name: "My Custom Attack"
    category: "PROMPT_INJECTION"
    complexity: "MEDIUM"
    prompt_template: |
      Test prompt: {{ harmful_instruction }}
    owasp_mapping: ["LLM-01"]
    expected_refusal: true
```

## ğŸ“ˆ Use Cases

### 1. **Pre-Deployment Testing**
Test models before production deployment

### 2. **Compliance Validation**
Ensure compliance with OWASP, ISO 42001, NIST AI RMF, EU AI Act

### 3. **Continuous Security Testing**
Run tests periodically (CI/CD integration)

### 4. **Red Team Exercises**
Identify vulnerabilities and safety gaps

### 5. **Attack Research**
Develop and test new attack techniques

### 6. **Model Comparison**
Compare security across different models

## ğŸ›¡ï¸ Security Considerations

- âš ï¸ **Use only on models you own or have permission to test**
- âš ï¸ **Never commit API keys to version control**
- âš ï¸ **Use environment variables for secrets**
- âš ï¸ **Review compliance requirements before testing**
- âš ï¸ **Log all test activities for audit trails**

## ğŸ“š Documentation

- **Getting Started**: [QUICKSTART.md](docs/QUICKSTART.md)
- **Prompt Intel Setup**: [PROMPTINTEL_LOCAL_SETUP.md](docs/PROMPTINTEL_LOCAL_SETUP.md)
- **Implementation**: [PROMPTINTEL_LOCAL_IMPLEMENTATION.md](PROMPTINTEL_LOCAL_IMPLEMENTATION.md)
- **Full API Reference**: [COMPLETE_REFERENCE.md](COMPLETE_REFERENCE.md)
- **Architecture**: [docs/DEVELOPER_GUIDE.md](docs/DEVELOPER_GUIDE.md)

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Create a feature branch
2. Make your changes
3. Run tests
4. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ“ Support

For issues, questions, or suggestions, please create a GitHub issue or contact the team.

---

**Built with â¤ï¸ for enterprise LLM security** | Version 1.0.0 | [GitHub](https://github.com/your-org/llm-security-testing-framework)
