# ğŸ“ Project Structure & Organization Guide

## Directory Layout

```
llm-security-testing-framework/
â”‚
â”œâ”€â”€ ğŸš€ QUICKSTART SCRIPTS (Choose based on your setup)
â”‚   â”œâ”€â”€ quickstart_local.py          â† Local GGUF Mistral (â­ YOUR SETUP)
â”‚   â”œâ”€â”€ quickstart_ollama.py         â† Ollama local models
â”‚   â”œâ”€â”€ quickstart_gemini.py         â† Google Gemini (free)
â”‚   â””â”€â”€ quickstart_huggingface.py    â† HuggingFace (deprecated endpoints)
â”‚
â”œâ”€â”€ ğŸ“‹ CONFIGURATION
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ config_local.yaml        â† Local GGUF settings (â­ YOUR SETUP)
â”‚       â”œâ”€â”€ config_ollama.yaml       â† Ollama settings
â”‚       â”œâ”€â”€ config_gemini.yaml       â† Gemini settings
â”‚       â”œâ”€â”€ config_huggingface.yaml  â† HuggingFace settings
â”‚       â”œâ”€â”€ config.yaml              â† Default config
â”‚       â””â”€â”€ test_suites.yaml         â† Test suite definitions
â”‚
â”œâ”€â”€ ğŸ”§ SOURCE CODE
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.py                  â† Framework entry point
â”‚       â”œâ”€â”€ orchestrator.py          â† Model orchestrator
â”‚       â”œâ”€â”€ attack_engine.py         â† Attack execution engine
â”‚       â”œâ”€â”€ evaluator.py             â† Result evaluation
â”‚       â”œâ”€â”€ reporter.py              â† Report generation
â”‚       â”œâ”€â”€ telemetry.py             â† Metrics & logging
â”‚       â”‚
â”‚       â””â”€â”€ adapters/
â”‚           â”œâ”€â”€ base.py              â† Adapter interface
â”‚           â”œâ”€â”€ local_gguf_adapter.py    â† Local GGUF (â­ NEW)
â”‚           â”œâ”€â”€ ollama_adapter.py    â† Ollama
â”‚           â”œâ”€â”€ gemini_adapter.py    â† Google Gemini
â”‚           â”œâ”€â”€ openai_adapter.py    â† OpenAI
â”‚           â”œâ”€â”€ anthropic_adapter.py â† Anthropic
â”‚           â”œâ”€â”€ huggingface_adapter.py â† HuggingFace
â”‚           â””â”€â”€ promptintel_adapter.py
â”‚
â”œâ”€â”€ ğŸ¯ ATTACK DEFINITIONS
â”‚   â””â”€â”€ attacks/
â”‚       â””â”€â”€ owasp_attacks.yaml       â† Attack library
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ OLLAMA_QUICKSTART.md         â† Ollama setup guide
â”‚   â”œâ”€â”€ LOCAL_GGUF_SETUP.md          â† Local GGUF guide (â­ NEW)
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md         â† This file
â”‚   â”œâ”€â”€ README.md                    â† Main readme
â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â”œâ”€â”€ QUICKSTART.md           â† General quickstart
â”‚   â”‚   â”œâ”€â”€ SETUP.md                â† Detailed setup
â”‚   â”‚   â”œâ”€â”€ API_KEYS.md             â† API key configs
â”‚   â”‚   â”œâ”€â”€ BATCH_TESTING.md        â† Batch testing
â”‚   â”‚   â”œâ”€â”€ DEVELOPER_GUIDE.md      â† Dev guide
â”‚   â”‚   â””â”€â”€ THREAT_MODEL.md         â† Security model
â”‚   â”‚
â”‚   â””â”€â”€ examples/
â”‚       â””â”€â”€ examples_batch_testing.py
â”‚
â”œâ”€â”€ ğŸ“Š OUTPUT DIRECTORIES (Auto-created)
â”‚   â”œâ”€â”€ reports/                    â† HTML & JSON reports
â”‚   â”œâ”€â”€ logs/                       â† Execution logs
â”‚   â””â”€â”€ src/reports/ & src/logs/    â† Backup locations
â”‚
â”œâ”€â”€ ğŸ“¦ DEPENDENCIES
â”‚   â”œâ”€â”€ requirements.txt             â† Python dependencies
â”‚   â”œâ”€â”€ requirements-local.txt       â† Additional for local GGUF
â”‚   â”œâ”€â”€ requirements-gpu.txt         â† GPU acceleration
â”‚   â””â”€â”€ Dockerfile                  â† Docker setup
â”‚
â””â”€â”€ ğŸ”— OTHER FILES
    â”œâ”€â”€ README.md
    â”œâ”€â”€ CHANGELOG.md
    â”œâ”€â”€ PROJECT_STATUS.md
    â”œâ”€â”€ api.txt
    â””â”€â”€ [other docs...]
```

---

## ğŸ¯ Quick Start Guide by Setup Type

### â­ Your Setup: Local GGUF Mistral

**Status:** âœ… Ready to use immediately

```bash
# 1. Install dependencies
pip install -r requirements.txt
pip install llama-cpp-python

# 2. Run the local quickstart
python quickstart_local.py

# 3. Check reports
# Reports will be generated in ./reports/report_*.html
```

**Config file:** `config/config_local.yaml`  
**Model location:** `C:\Users\acer\Desktop\Intership@quinine\official Work-week 1\My work\llm_security_assessment\models\mistral-7b-instruct-v0.2.Q4_K_M.gguf`

---

### Alternative Setup: Ollama

**Status:** âœ… Also configured

```bash
# 1. Install & start Ollama
ollama serve

# 2. In another terminal
ollama pull mistral
python quickstart_ollama.py
```

**Config file:** `config/config_ollama.yaml`

---

### Alternative Setup: Google Gemini

**Status:** âœ… Configured

```bash
# 1. Get free API key from https://ai.google.dev/pricing

# 2. Set environment variable
$env:GEMINI_API_KEY = "your_key"

# 3. Run
python quickstart_gemini.py
```

**Config file:** `config/config_gemini.yaml`

---

## ğŸ“‹ File Organization Logic

### Quickstart Scripts (`*.py` at root)
- **Purpose:** Entry points for different setups
- **Who uses:** End users/testers
- **Action:** Choose ONE based on your setup
- **Examples:**
  - `quickstart_local.py` - Local models â­
  - `quickstart_ollama.py` - Ollama servers
  - `quickstart_gemini.py` - Cloud APIs

### Configuration Files (`config/`)
- **Purpose:** Define model setup, attack categories, execution params
- **Who uses:** Framework, quickstart scripts
- **Format:** YAML for readability
- **Examples:**
  - `config_local.yaml` - Local GGUF paths and settings
  - `config_ollama.yaml` - Ollama endpoints
  - `config_gemini.yaml` - API keys and models

### Adapters (`src/adapters/`)
- **Purpose:** Model-specific integrations
- **Who uses:** Orchestrator (internal)
- **Logic:**
  - `base.py` - Interface all adapters implement
  - `*_adapter.py` - Specific model implementations
  - `local_gguf_adapter.py` - Your local setup â­

### Attack Library (`attacks/`)
- **Purpose:** Define security test cases
- **Format:** YAML (easy to modify)
- **Examples:** Prompt injection, jailbreaks, PII leakage

### Reports & Logs (Auto-created)
- **Purpose:** Test results and execution details
- **Location:** `./reports/` and `./logs/`
- **Formats:** HTML (visual), JSON (data), JSONL (logs)

---

## ğŸ”„ Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ quickstart_localâ”‚ (Entry point)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ config_local.yaml    â”‚ (Load settings)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM SecurityTest     â”‚
â”‚ Framework (main.py)  â”‚ (Initialize)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â–º Orchestrator (Register models)
         â”‚        â”‚
         â”‚        â””â”€â–º LocalGGUFAdapter (Load model)
         â”‚
         â”œâ”€â”€â”€â”€â–º AttackEngine (Load attacks from attacks/)
         â”‚
         â””â”€â”€â”€â”€â–º EvaluationPipeline (Evaluate results)
                 â”‚
                 â–¼
         Reporter (Generate HTML & JSON)
                 â”‚
                 â–¼
          ./reports/report_*.html
          ./reports/report_*.json
          ./logs/results.jsonl
```

---

## ğŸ› ï¸ Key Files for Your Setup

| File | Purpose | Action |
|------|---------|--------|
| `quickstart_local.py` | Entry point for local GGUF | Run this â† |
| `config/config_local.yaml` | Settings for your model | Edit if path changes |
| `src/adapters/local_gguf_adapter.py` | GGUF model interface | Use as-is |
| `src/main.py` | Framework logic | Use as-is |
| `attacks/owasp_attacks.yaml` | Test cases | Customize if needed |

---

## ğŸ“Š Output Files Explained

After running tests, you'll find:

```
reports/
â”œâ”€â”€ report_a1b2c3d4-e5f6-7890-abcd-ef1234567890.html  â† Open in browser
â”œâ”€â”€ report_a1b2c3d4-e5f6-7890-abcd-ef1234567890.json  â† Raw data
â”œâ”€â”€ report_x1y2z3w4-q5r6-7890-abcd-ef1234567890.html
â””â”€â”€ report_x1y2z3w4-q5r6-7890-abcd-ef1234567890.json

logs/
â””â”€â”€ results.jsonl  â† Execution log (one JSON per line)
```

### Report Contents:
- **Attacks tested** - Categories and complexity levels
- **Compliance scores** - Refusal, partial, full compliance percentages
- **Vulnerabilities found** - Specific attack successes
- **Response analysis** - Model behavior details
- **Execution metrics** - Duration, latency, token counts

---

## âœ¨ All Available Quickstarts

| Script | Setup | Speed | Cost | Best For |
|--------|-------|-------|------|----------|
| `quickstart_local.py` | â­ Local GGUF | Medium | FREE | Your use case |
| `quickstart_ollama.py` | Local (via Ollama) | Medium | FREE | Flexibility |
| `quickstart_gemini.py` | Google Cloud | Fast | FREE tier | Quick tests |
| `quickstart_huggingface.py` | HuggingFace API | Fast | FREE | Testing APIs |
| `examples_batch_testing.py` | Advanced | - | Varies | Multiple configs |

---

## ğŸš€ Next Steps

1. âœ… Run: `python quickstart_local.py`
2. â³ Wait for tests to complete
3. ğŸ“Š Open `reports/report_*.html` in browser
4. ğŸ“ˆ Analyze results
5. ğŸ”§ Modify `config/config_local.yaml` if needed
6. ğŸ¯ Rerun tests with different settings

---

## ğŸ“ Notes

- **Model file path:** Already configured in `config_local.yaml`
- **GPU support:** Optional - install `llama-cpp-python[gpu]` for faster inference
- **Memory:** Q4_K_M quantization uses ~6GB GPU/CPU memory
- **First run:** Slower as model loads; subsequent runs faster
- **Customization:** Edit `config_local.yaml` to change test categories/complexity

---

**Your project is now organized and ready to go! Run `python quickstart_local.py` to start testing.** ğŸ‰
